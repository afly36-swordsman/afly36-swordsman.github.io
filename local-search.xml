<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>草稿</title>
    <link href="/2023/11/29/Write/"/>
    <url>/2023/11/29/Write/</url>
    
    <content type="html"><![CDATA[<p>草稿。</p>]]></content>
    
    
    <categories>
      
      <category>Default</category>
      
    </categories>
    
    
    <tags>
      
      <tag>draft</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>文献整理·开山篇</title>
    <link href="/2023/11/25/Papers/"/>
    <url>/2023/11/25/Papers/</url>
    
    <content type="html"><![CDATA[<h2 id="tardal">TarDAL</h2><h3 id="title">Title</h3><p>Target-aware Dual Adversarial Learning and a Multi-scenarioMulti-modality Benchmark to Fuse Infrared and Visible for ObjectDetection [CVPR]</p><h3 id="motivation">Motivation</h3><p>Previous approaches:</p><div class="code-wrapper"><pre><code class="hljs mipsasm"><span class="hljs-number">1</span>.Aiming <span class="hljs-built_in">at</span> generating an image of high visual quality<span class="hljs-number">2</span>.<span class="hljs-keyword">Discover </span>commons underlying the two modalities <span class="hljs-keyword">and </span>fuseupon the common space <span class="hljs-keyword">either </span><span class="hljs-keyword">by </span>iterative optimization <span class="hljs-keyword">or </span>deep networks<span class="hljs-number">3</span>.Neglect that modality <span class="hljs-keyword">differences </span>implying the complementary infomationwhich <span class="hljs-keyword">extremely </span>important for <span class="hljs-keyword">both </span>fusion <span class="hljs-keyword">and </span><span class="hljs-keyword">subsequent </span>detection task</code></pre></div><h3 id="info">Info</h3><div class="code-wrapper"><pre><code class="hljs maxima">Visible <span class="hljs-built_in">image</span>, provides rich details with high spatial <span class="hljs-built_in">resolution</span>(under welldefined lighting conditions)</code></pre></div><div class="code-wrapper"><pre><code class="hljs sqf">Infrared <span class="hljs-built_in">image</span>, capturing ambient temperature variations emitted <span class="hljs-keyword">from</span> objects, highlight structures of thermal <span class="hljs-built_in">targets</span> (insensive <span class="hljs-keyword">to</span> lighting changes)</code></pre></div><p>Their evident appearance discrepancy, it's challenging to fusevisually appealing images and/or to support higher-level vision tasks(by making full use of the complementary info from the infrared andvisible images)</p><p>The fusion emphasizes more on "seeking commons" but neglect thedifferences of these two modalities on presenting structure info oftargets and textural details of ambient background.</p><h3 id="method">Method</h3><p>Fusion network:</p><div class="code-wrapper"><pre><code class="hljs mipsasm">Composed of one generator <span class="hljs-keyword">and </span>two target-aware <span class="hljs-keyword">discriminators, </span><span class="hljs-keyword">and </span>a commonly used detection network  [Detection-<span class="hljs-keyword">oriented </span>fusion]<span class="hljs-symbol"></span><span class="hljs-symbol">Discriminator:</span><span class="hljs-keyword">Distinguishes </span>foreground(structure infomation of targets), i.e., thermal targets(infrared image), <span class="hljs-keyword">and </span><span class="hljs-keyword">differentiates</span><span class="hljs-keyword"></span>the <span class="hljs-keyword">background, </span>i.e., textural details(visible image)Derive a cooperative training <span class="hljs-keyword">scheme</span></code></pre></div><h3 id="structure-diagram">Structure diagram</h3><figure><img src="/img/stage1/11.png"alt="Methodology framework: (a) bilevel optimization formulation for fusion and detection, (b) target-aware adversarial dual learning network for fusion, and (c) cooperative training scheme." /><figcaption aria-hidden="true">Methodology framework: (a) bileveloptimization formulation for fusion and detection, (b) target-awareadversarial dual learning network for fusion, and (c) cooperativetraining scheme.</figcaption></figure><figure><img src="/img/stage1/12.png" alt="The details of network" /><figcaption aria-hidden="true">The details of network</figcaption></figure><figure><img src="/img/stage1/13.png"alt="The architectures of generator and discriminator" /><figcaption aria-hidden="true">The architectures of generator anddiscriminator</figcaption></figure><h3 id="loss-function">Loss function</h3><p>Detection network backbone: YOLOv5</p><p>Generator: 1.Structural similarity index (SSIM)</p><blockquote><p>Contributes to generate a fused image that preserves overallstructures and maintains a similar intensity distribution as sourceimages.</p></blockquote><figure><img src="/img/stage1/14.png" alt="Generator loss SSIM" /><figcaption aria-hidden="true">Generator loss SSIM</figcaption></figure><p>2.Pixel loss (based on the saliency degree weight (SDW))</p><blockquote><p>To balance the pixel intensity distribution of source images</p></blockquote><p><img src="/img/stage1/15.png" alt="Pixel Loss" /> w1, w2 arecalculated by saliency value of x and y.</p><p>Target and detail discriminators: Wasserstein divergence (with targetmask m)</p><blockquote><p>The target discriminator <span class="math inline">\(D_T\)</span> isused to distinguish the foreground thermal targets of fused result tothe infrared while the detail discriminator <spanclass="math inline">\(D_D\)</span> contributes to distinguish thebackground details of fused result to the visible.</p></blockquote><figure><img src="/img/stage1/16.png" alt="Discriminator loss" /><figcaption aria-hidden="true">Discriminator loss</figcaption></figure><h2 id="seafusion">SeAFusion</h2><h3 id="title-1">Title</h3><p>Image fusion in the loop of high-level vision tasks: A semantic-awarereal-time infrared and visible image fusion network [Image Fusion]</p><h3 id="intro">Intro</h3><p>The infrared sensor captures thermal radiation emitted from objects,which could highlight salient targets, but the infrared image neglectstexture and is vulnerable to noise.</p><p>The visible sensor captures reflective light infomation, the visibleimage usually contains abundant texture and structure info, but issensitive to the environment, such as illumination and occlusion.</p><p>Complementary info: to fuse Ir and Vis image, to generate a desiredimage.</p><p>Fused image has been broadly used as a preprocessing module forhigh-level vision tasks, e.g., object detection, tracking, semanticsegmentation.</p><h3 id="motivation-1">Motivation</h3><p>Pressing challenges:</p><div class="code-wrapper"><pre><code class="hljs livecodeserver"><span class="hljs-number">1.</span>The existing fusion algorithms are inclined <span class="hljs-built_in">to</span> pursue better visual quality<span class="hljs-keyword">and</span> higher evaluation metrics but seldom systematically considerwhether fused image can facilitate high-level vision tasksSome studies: cannot effectively enhance/boost <span class="hljs-keyword">the</span> semantic info <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> fused image<span class="hljs-number">2.</span>Neither visual comparison nor quantitative evaluation (evaluation manners)reflects <span class="hljs-keyword">the</span> facilitation <span class="hljs-keyword">of</span> fused images <span class="hljs-keyword">for</span> high-level vision tasks<span class="hljs-number">3.</span>Not <span class="hljs-keyword">effective</span> <span class="hljs-keyword">in</span> extracting fine-grained detail features<span class="hljs-number">4.</span>Ignore <span class="hljs-keyword">the</span> demand <span class="hljs-keyword">for</span> real-<span class="hljs-built_in">time</span> image fusion</code></pre></div><p>Ours network:</p><p>SeAFusion, can be used for achieving real-time Ir &amp; Vis imagefusion</p><h3 id="method-1">Method</h3><div class="code-wrapper"><pre><code class="hljs pgsql"><span class="hljs-number">1.</span>Simultaneously obtaining superior performance <span class="hljs-keyword">in</span><span class="hljs-keyword">both</span> image fusion <span class="hljs-keyword">and</span> high-<span class="hljs-keyword">level</span> vision tasks.<span class="hljs-number">2.</span>A segmentation network <span class="hljs-keyword">to</span> predict the segmentation results<span class="hljs-keyword">on</span> fused images, which <span class="hljs-keyword">is</span> utilized <span class="hljs-keyword">to</span> construct semantic loss(<span class="hljs-keyword">is</span> leveraged <span class="hljs-keyword">to</span> guide the training <span class="hljs-keyword">of</span> the fusion network via back-propagation, so the loss can flow back <span class="hljs-keyword">to</span> the image fusion module<span class="hljs-keyword">to</span> forcing fused images <span class="hljs-keyword">to</span> contain more semantic infomation).<span class="hljs-number">3.</span><span class="hljs-type">Real</span>-<span class="hljs-type">time</span>: light-weight network based <span class="hljs-keyword">on</span> GRDB (gradient residual dense block)<span class="hljs-keyword">to</span> boost the description ability <span class="hljs-keyword">for</span> fine-grained details <span class="hljs-keyword">and</span> achieve feature reuse.<span class="hljs-number">4.</span>The authors proposed a joint low-<span class="hljs-keyword">level</span> <span class="hljs-keyword">and</span> high-<span class="hljs-keyword">level</span> adaptive training strategy<span class="hljs-keyword">to</span> achieve simultaneously impressive performance <span class="hljs-keyword">in</span> <span class="hljs-keyword">both</span>image fusion <span class="hljs-keyword">and</span> various high-<span class="hljs-keyword">level</span> vision tasks.</code></pre></div><h3 id="structure-diagram-1">Structure diagram</h3><figure><img src="/img/stage1/21.png"alt="The overall framework of the proposed semantic-aware infrared and visible image fusion algorithm." /><figcaption aria-hidden="true">The overall framework of the proposedsemantic-aware infrared and visible image fusion algorithm.</figcaption></figure><figure><img src="/img/stage1/22.png"alt="The architecture of the real-time infrared and visible image fusion network based on gradient residual dense block." /><figcaption aria-hidden="true">The architecture of the real-timeinfrared and visible image fusion network based on gradient residualdense block.</figcaption></figure><figure><img src="/img/stage1/23.png"alt="The specific devise of the gradient residual dense block. The Sobel operator is selected as the Gradient Operator to extract fine-grained detail information of feature maps." /><figcaption aria-hidden="true">The specific devise of the gradientresidual dense block. The Sobel operator is selected as the GradientOperator to extract fine-grained detail information of featuremaps.</figcaption></figure><h3 id="分析">分析</h3><figure><img src="/img/stage1/24.png" alt="Analysis1: fusion network" /><figcaption aria-hidden="true">Analysis1: fusion network</figcaption></figure><figure><img src="/img/stage1/25.png" alt="Analysis2: segmentation module" /><figcaption aria-hidden="true">Analysis2: segmentationmodule</figcaption></figure><figure><img src="/img/stage1/26.png" alt="Algorithm" /><figcaption aria-hidden="true">Algorithm</figcaption></figure><p>注：分割网络的backbone采用YOLOv5网络</p><h2 id="segmif">SegMiF</h2><h3 id="title-2">Title</h3><p>Multi-interactive Feature Learning and a Full-time Multi-modalityBenchmark for Image Fusion and Segmentation [ICCV]</p><h3 id="abstract">Abstract</h3><p>Early efforts boost performance for only one task.</p><p>This paper, SegMiF can dual-task correlation to promote theperformance of both tasks (fusion and segmentation).</p><h3 id="intro-1">Intro</h3><p>Contributions:</p><div class="code-wrapper"><pre><code class="hljs sql"><span class="hljs-number">1.</span>SegMiF <span class="hljs-keyword">contains</span> two modules, i.e., <span class="hljs-keyword">fusion</span> network<span class="hljs-keyword">and</span> common segmentation network.<span class="hljs-number">2.</span>Hierarchical interactive attention (HIA) block. Fine<span class="hljs-operator">-</span>grained mapping <span class="hljs-keyword">of</span> <span class="hljs-keyword">all</span> the vital infomation <span class="hljs-keyword">between</span> <span class="hljs-keyword">fusion</span> <span class="hljs-keyword">and</span> segmentation. Modality<span class="hljs-operator">-</span><span class="hljs-operator">/</span>Semantic<span class="hljs-operator">-</span> oriented features can be fully mutual<span class="hljs-operator">-</span>interactive(bridge the feature gap <span class="hljs-keyword">between</span> <span class="hljs-keyword">fusion</span> <span class="hljs-keyword">and</span> segmentation).<span class="hljs-number">3.</span><span class="hljs-keyword">Dynamic</span> weight factor, automatically adjust the <span class="hljs-keyword">corresponding</span> weights<span class="hljs-keyword">of</span> <span class="hljs-keyword">each</span> task (optimal parameters).<span class="hljs-number">4.</span>Interactive feature training scheme.<span class="hljs-number">5.</span>Construct an imaging <span class="hljs-keyword">system</span> (benchmark).</code></pre></div><h3 id="structure-diagram-2">Structure diagram</h3><figure><img src="/img/stage1/31.png"alt="Workflow of the proposed SegMiF. The left part depicts the latent interactive relationship between image fusion and segmentation. The middle part plots the concrete architecture of the SegMiF. The right part details the components of proposed hierarchical interactive attention." /><figcaption aria-hidden="true">Workflow of the proposed SegMiF. The leftpart depicts the latent interactive relationship between image fusionand segmentation. The middle part plots the concrete architecture of theSegMiF. The right part details the components of proposed hierarchicalinteractive attention.</figcaption></figure><figure><img src="/img/stage1/32.png" alt="Partial zoom" /><figcaption aria-hidden="true">Partial zoom</figcaption></figure><h3 id="分析-1">分析</h3><figure><img src="/img/stage1/33.png" alt="Fusion network and DRDB module" /><figcaption aria-hidden="true">Fusion network and DRDBmodule</figcaption></figure><p><img src="/img/stage1/34.png"alt="Detailed architectures of SoAM and MoAM" />注：分割网络是论文[SegFormer: Simple and Efficient Design for SemanticSegmentation with Transformers]的内容</p><p>分割网络： <img src="/img/stage1/36.png"alt="Segmentation network" /></p><h4 id="hia">HIA</h4><p>1.SoAM (Semantic-oriented attention module)</p><blockquote><p>SoAM utilizes the token <spanclass="math inline">\(F_{seg}^{s}\)</span> to generate the query <spanclass="math inline">\(Q_s\)</span>, which represents the inhere semanticinformation that needs to be enhanced.</p></blockquote><blockquote><p>The global context representation of each can be calculated by as<span class="math inline">\(K_{ir}^{T}\cdot V_{ir} (G_{ir})\)</span> and<span class="math inline">\(K_{vis}^{T}\cdot V_{vis} (G_{vis})\)</span>, 其中K, V ∈ {<span class="math inline">\(F_{ir}^{s}\)</span>, <spanclass="math inline">\(F_{vis}^{s}\)</span>} <spanclass="math inline">\(S_{ir} = Q_s\cdot G_{ir}\)</span>, <spanclass="math inline">\(S_{vis} = Q_s\cdot G_{vis}\)</span></p></blockquote><blockquote><p>SoAM to provide more semantic attention for the modality feature.</p></blockquote><p>2.MoAM (Modality-oriented attention module)</p><blockquote><p>MoAM introduce two modality queries <spanclass="math inline">\(Q_{ir}\)</span> and <spanclass="math inline">\(Q_{vis}\)</span> ∈ {<spanclass="math inline">\(F_{ir}^{m}\)</span>, <spanclass="math inline">\(F_{vis}^{m}\)</span>}</p></blockquote><blockquote><p>The global context of segmentation <spanclass="math inline">\(G_s\)</span> by <spanclass="math inline">\(K_{s}^{T}\cdot V_s\)</span> <spanclass="math inline">\(M_{ir} = Q_{ir}\cdot G_s\)</span>, <spanclass="math inline">\(M_{vis} = Q_{vis}\cdot G_s\)</span></p></blockquote><blockquote><p>MoAM to investigate the significant feature from semanticcontexts.</p></blockquote><h4 id="目标函数">目标函数</h4><figure><img src="/img/stage1/35.png" alt="Joint formulation" /><figcaption aria-hidden="true">Joint formulation</figcaption></figure><p>损失函数： <img src="/img/stage1/37.png" alt="Loss" /></p><div class="code-wrapper"><pre><code class="hljs armasm">损失函数中涉及了两个常用的概念：结构相似度、显著性图<span class="hljs-number">1</span>.结构相似度SSIM主要用来衡量两幅图亮度、对比度和结构的相似性  详见<span class="hljs-string">&quot;专业笔记&quot;</span>中所述<span class="hljs-number">2</span>.显著性图主要用来计算MSE损失中的显著性参数m  源自论文: Infrared <span class="hljs-keyword">and</span> visible image fusion based on visual saliency <span class="hljs-meta">map</span>            <span class="hljs-keyword">and</span> weighted least square optimization</code></pre></div><h3 id="相关内容">相关内容</h3><div class="code-wrapper"><pre><code class="hljs mathematica">当<span class="hljs-variable">CNN</span>层数变深时，输出到输入的路径就会变得很长。梯度反向传播，到达输入层可能就会消失。<span class="hljs-variable">DenseNet</span>是一种深度卷积神经网络，引入密集连接（<span class="hljs-variable">Dense</span> <span class="hljs-variable">Connection</span>）将前面所有层与后面的层建立密集连接。与<span class="hljs-variable">ResNet</span>的关键区别是，<span class="hljs-variable">ResNet</span>是简单相加，<span class="hljs-variable">DenseNet</span>是进行连接。<span class="hljs-variable">DenseNet</span>通过基本构建单元<span class="hljs-variable">Dense</span> <span class="hljs-built_in">Block</span>实现稠密连接对特征进行重用，实现信息共享，并能增强梯度流动，避免梯度消失。过渡层（<span class="hljs-variable">Transition</span> <span class="hljs-variable">Layer</span>）控制通道数（稠密块会带来通道数的增加），防止模型过于复杂。<span class="hljs-variable">DenseNet</span>在模型精度和泛化能力上通常表现优异，训练更稳定，但结构仍比较复杂，需要消耗较多的计算资源和时间，内存占用大。<span class="hljs-variable">ResNet</span>（<span class="hljs-variable">Residual</span> <span class="hljs-variable">Neural</span> <span class="hljs-variable">Network</span>）是基于残差学习框架的神经网络，其在前向网络中增加了一些快捷连接<span class="hljs-variable">Shortcut</span><span class="hljs-punctuation">(</span><span class="hljs-built_in">Short</span><span class="hljs-punctuation">)</span> <span class="hljs-variable">Connection</span><span class="hljs-operator">/</span><span class="hljs-built_in">Skip</span> <span class="hljs-variable">Connection</span>，这些连接会跳过某些层，将数据直接传到之后的层。<span class="hljs-variable">ResNet</span>对网络深度增加带来的梯度消失或爆炸、网络退化（由于训练和测试误差的积累导致正确率趋于饱和甚至下降，与过拟合（训练误差小，测试误差大，泛化能力差）不同）等问题具有一定的作用，增加了非线性，一定程度上抑制了语义间隙的影响，但模型表现可能略逊一筹。残差块（<span class="hljs-variable">Residual</span> <span class="hljs-built_in">Block</span>）是<span class="hljs-variable">ResNet</span>的基本组成成分。</code></pre></div><div class="code-wrapper"><pre><code class="hljs arcade">空洞卷积（Dilated/Atrous Convolution）可以增加卷积核的尺寸，如原本<span class="hljs-number">3</span>*<span class="hljs-number">3</span>的卷积核可以扩充至<span class="hljs-number">5</span>*<span class="hljs-number">5</span>，但有效的参数个数不变，仍为<span class="hljs-number">9</span>个，剩余的位置不予考虑（空洞/零），利用超参数“扩张率”来定义卷积核处理数据时各值的间距（可以理解为空洞数），在扩大了感受野的同时，避免了Pooling操作，从而保持分辨率不变。PS：正常扩大感受野会带来计算量的增加，后面进行池化的降采样处理可以降低计算量，但是空间分辨率也随之降低了。感受野（Receptive Field）越大，捕获的图像区域越大，对图像全局的特征提取能力也就越强。而且对于目标检测任务而言，最后一层特征图（<span class="hljs-built_in">Feature</span> <span class="hljs-built_in">Map</span>）的感受野大小要大于等于输入图像大小，否则分类性能会不理想。一般而言，感受野越大、网络越深，对复杂问题求解的模型性能越好。</code></pre></div>]]></content>
    
    
    <categories>
      
      <category>Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>summarize</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>专业笔记</title>
    <link href="/2023/11/25/Professional/"/>
    <url>/2023/11/25/Professional/</url>
    
    <content type="html"><![CDATA[<h3 id="terminology-index">Terminology Index</h3><div class="code-wrapper"><pre><code class="hljs mipsasm">IQA：图像质量评价，image quality assessment上游任务，预训练模型，对应 low-level task；下游任务，具体的 task，对应 high-level taskAblation study：消融实验，移除 Model 的部分<span class="hljs-string">&quot;feature&quot;</span>（控制变量法），对比研究模型的性能FPS：每秒传输帧数，frames per secondFine-tune：微调光谱（Spectrum）：复色光经过分光成为单色光，经成像系统得到按波长或者频率依次排列的光学图像多光谱（<span class="hljs-keyword">Multispectrum）：同时获取多个光学频谱波段（大于3个），在可见光基础上向红外、紫外两个方向扩展</span><span class="hljs-keyword"></span>高光谱（Hyperspectrum）：包含成百上千的波段，可以捕获和分析一片空间区域内“逐点”的光谱Embedding：在深度学习中利用线性或非线性转换，对复杂的数据进行自动特征抽取，并将其features表示为向量形式，以便于输入到网络中进行处理。这个过程被称之为<span class="hljs-string">&quot;Embedding&quot;</span><span class="hljs-keyword">BN(Batch </span><span class="hljs-keyword">Normalization)：像深度学习模型输入数据时，要对data进行归一化操作，如均值为0、方差为1的规范化处理，</span><span class="hljs-keyword"></span>否则过大的特征会“淹没”小特征。这种情况不仅会在输入模型时出现，也会在层与层中存在，因为随着数据的逐级传播，经过损失函数（如Softmax）后会使得特征之间的差异变大，逐渐累积会对最终结果造成较大的影响。所以需要对层间数据也进行规范化，<span class="hljs-keyword">BN就是在两个隐藏层之间对数据在Batch方向进行Norm处理，</span><span class="hljs-keyword"></span>并且最后加入了<span class="hljs-keyword">Scale </span><span class="hljs-keyword">and </span><span class="hljs-keyword">Shift操作，以提高网络对Norm的学习能力。</span><span class="hljs-keyword"></span>LN(Layer <span class="hljs-keyword">Normalization)：与BN不同之处在于，LN是在数据的Channel方向进行Norm归一化操作。</span><span class="hljs-keyword"></span><span class="hljs-keyword">BN是对一个batch的数据的对应位置上所有的feature进行归一化，而LN是对每个sample进行归一化。</span><span class="hljs-keyword"></span>在三维视觉任务的情形下，可以理解为：<span class="hljs-keyword">BN对每一张图片对应位置的像素做Norm处理，LN则是对单幅图像的整体做Norm。</span><span class="hljs-keyword"></span>但通常在数据传入Model前会进行数据的归一化处理，因此通常不会再使用LN。</code></pre></div><p><img src="/img/stage1/bn.png" alt="Batch Norm" /> <imgsrc="/img/stage1/ln.png" alt="Layer Norm" /></p><h3 id="距离度量">距离度量</h3><div class="code-wrapper"><pre><code class="hljs arcade">欧氏距离（Euclidean <span class="hljs-built_in">Distance</span>）：两点连线长度城区距离（曼哈顿距离，Manhattan <span class="hljs-built_in">Distance</span>）：直角移动距离，不涉及对角线棋盘距离（切比雪夫距离，Chebyshev <span class="hljs-built_in">Distance</span>）：沿某个轴的距离最大值汉明距离（Hamming <span class="hljs-built_in">Distance</span>）：比较两等长二进制串不同值的个数余弦相似度（Cosine Similarity）：两向量夹角余弦表示距离，与内积有关</code></pre></div><h3 id="图片格式">图片格式</h3><div class="code-wrapper"><pre><code class="hljs mipsasm"><span class="hljs-keyword">JPEG，静态图像压缩标准，压缩比越高，质量越差</span><span class="hljs-keyword"></span><span class="hljs-keyword">JPG，与JPEG类似，相当于简化版，去除了相机的拍照参数等</span><span class="hljs-keyword"></span>PNG，无损压缩，位图片格式GIF，静态、动态图像，如动图、表情包TIFF，无失真压缩，占用空间较大TGA，兼顾 <span class="hljs-keyword">BMP </span>图像的质量与 <span class="hljs-keyword">JPEG </span>的体积<span class="hljs-keyword">BMP，位图 </span><span class="hljs-keyword">Bitmap，不采用压缩，占用空间大</span><span class="hljs-keyword"></span>SVG，二维矢量图形格式RAW，经 CMOS 或 CCD 图像感应器将捕捉到的光信号转换为数字信号的原始数据HDR，高动态范围图像，High-Dynamic Range，记录了照明信息</code></pre></div>]]></content>
    
    
    <categories>
      
      <category>Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>basic</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔系列5：数码</title>
    <link href="/2023/11/25/NumericalCode/"/>
    <url>/2023/11/25/NumericalCode/</url>
    
    <content type="html"><![CDATA[<p>正在施工中……</p>]]></content>
    
    
    <categories>
      
      <category>Life</category>
      
    </categories>
    
    
    <tags>
      
      <tag>functional</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔系列4：ICT</title>
    <link href="/2023/11/25/ICT/"/>
    <url>/2023/11/25/ICT/</url>
    
    <content type="html"><![CDATA[<h3 id="显示器接口">显示器接口</h3><ol type="1"><li>VGA接口</li></ol><blockquote><p>采用模拟协议，常用于老式显示器。目前不常用了，像一个四圆角梯形。</p></blockquote><figure><imgsrc="https://pica.zhimg.com/80/v2-9260a9e7bb2d44713e0976a8ac2ee667_1440w.webp?source=2c26e567"title="VGA接口" alt="VGA接口" /><figcaption aria-hidden="true">VGA接口</figcaption></figure><ol start="2" type="1"><li>DVI接口</li></ol><blockquote><p>有很多种类，算是VGA到HDMI的过渡产物。</p></blockquote><figure><imgsrc="https://pica.zhimg.com/80/v2-5dd3c4951a6a5c178e773deb1ba6b422_1440w.webp?source=2c26e567"title="DVI-D接口" alt="DVI-D接口" /><figcaption aria-hidden="true">DVI-D接口</figcaption></figure><ol start="3" type="1"><li>HDMI接口</li></ol><blockquote><p>音视频同时传输，支持高动态范围HDR成像，很常用，像带两个弯角的矩形。</p></blockquote><figure><imgsrc="https://picx.zhimg.com/80/v2-50888e26e96dafd6b0b5df25451923b9_1440w.webp?source=2c26e567"title="HDMI接口" alt="HDMI接口" /><figcaption aria-hidden="true">HDMI接口</figcaption></figure><ol start="4" type="1"><li>DP接口</li></ol><blockquote><p>DP(Digital Port)，也很常用，是HDMI的竞争对手，有很大的发展前景。</p></blockquote><figure><imgsrc="https://picx.zhimg.com/80/v2-3c1c4109ffc3f017bfdea221a49b77ca_1440w.webp?source=2c26e567"title="DP接口" alt="DP接口" /><figcaption aria-hidden="true">DP接口</figcaption></figure><h3 id="dns">DNS</h3><p>DNS(Domain NameSystem，域名系统)，用于域名解析，是因特网上作为域名和IP地址互相映射的一个分布式数据库，能让用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。</p><p><a href="https://zhuanlan.zhihu.com/p/186028919"title="什么是DNS？">点击查看详情</a></p><h3 id="路由器相关">路由器相关</h3><h4 id="直连">直连</h4><p>用一根网线连接两台主机的网口，可以相互发送和接收数据。<div class="code-wrapper"><pre><code class="hljs">多台主机通信怎么办？</code></pre></div></p><h4 id="集线器">集线器</h4><p>集线器(HUB)，将网线集结起来，实现初级的网络互通，工作在物理层，半双工通信。同时可以将信号放大后再传输以扩大传输距离。<div class="code-wrapper"><pre><code class="hljs 1c">集线器以广播形式以<span class="hljs-string">&quot;泛红转发&quot;</span>来发送数据，无法分辨具体的主机。</code></pre></div></p><h4 id="交换机">交换机</h4><p>交换机(Switch)，在集线器原有功能上，增加了自动寻址能力和交换作用，通过学习MAC地址（MAC地址表），查找对应的端口号，建立临时交换路径进行收发数据，工作在数据链路层，全双工通信。<div class="code-wrapper"><pre><code class="hljs">要求交换机端口上所有主机在同一个子网中。不同网段的主机怎么通信？</code></pre></div></p><h4 id="路由器">路由器</h4><p>路由器(Router)，连接不同类型的网络并能选择数据传输的IP路径，充当网关的角色，能在多网络互联环境中建立灵活的连接，工作在网络层。<div class="code-wrapper"><pre><code class="hljs arduino">家里拉了一条宽带（一条网线，现在多为光纤），只能一个人享受上网。如果要多设备连接网络，或者享受无线上网(<span class="hljs-built_in">WiFi</span>)，那么就需要安装路由器实现IP地址分配、网络共享和无线网使用（无线路由器），甚至进行网络加速（增强）。</code></pre></div></p><h4 id="猫">猫</h4><p>猫(Modem)，即光猫，调制解调器，进行光电转换。为了取代之前慢速的电话线上网，目前运营商多采用光纤传输，利用高速的光信号（会被限速，按你交的钱让你使用相应的带宽）进行数据传输。光信号无法直接被设备利用，经过光猫，将其转换为数字信号，即可被设备使用。</p><h4 id="ipmac地址">IP/MAC地址</h4><p>IP(InternetProtocol)，即互联网协议地址，为互联网上每一个网络和每一台主机配置唯一的逻辑地址，与物理地址区分。</p><p>IP地址分为IPv4和IPv6，IPv4使用32位（4字节）地址，IPv6地址长度为128位。最初设计互联网络时，为了便于寻址和层次化构造网络，每个IP地址包括两个标识码（ID），也就是网络ID和主机ID。同一个物理网络上的所有主机都使用同一个网络ID，网络上的一个主机（包括网络上工作站，服务器和路由器等）有一个主机ID与其对应。以IPv4地址为例，IP地址分为：1、公有地址(Publicaddress)，我们通过公有IP地址是可以实现直接访问因特网的。2、私有地址(Privateaddress)，分为五类：A类、B类、C类、D类、E类。其中，A、B、C类私有地址是由InternetNIC公司在全球范围内统一分配的，D、E类为特殊地址。<div class="code-wrapper"><pre><code class="hljs dns"><span class="hljs-keyword">A</span>类IP地址(适用于大型网络)的网络的标识(网络ID)长度为<span class="hljs-number">8</span>位，主机标识(主机ID)长度为<span class="hljs-number">24</span>位，它的范围：<span class="hljs-number">1.0.0.1</span>到<span class="hljs-number">127.255.255.254</span>；B类IP地址(适用于中型网络)的网络ID为<span class="hljs-number">16</span>位，主机ID长度为<span class="hljs-number">16</span>位，它的范围：<span class="hljs-number">128.0.0.1</span>-<span class="hljs-number">191.255.255.254</span>；C类IP地址(适用于小型网络)网络ID为<span class="hljs-number">24</span>位，主机ID长度为<span class="hljs-number">8</span>位，它的范围：<span class="hljs-number">192.0.0.1</span>-<span class="hljs-number">223.255.255.254</span>；D类地址被叫做多播地址(multicast address)，即组播地址，它的范围：<span class="hljs-number">224.0.0.0</span>到<span class="hljs-number">239.255.255.255</span>；E类地址主要用于Internet试验和开发，它的范围：<span class="hljs-number">240.0.0.0</span>~<span class="hljs-number">255.255.255.255</span></code></pre></div></p><p>MAC地址（Media Access ControlAddress）的全称叫做媒体访问控制地址，也称作局域网地址、以太网地址或者物理地址。MAC地址用于在网络中唯一标示一个网卡，一台设备若有一或多个网卡，则每个网卡都需要并会有一个唯一的MAC地址。MAC地址共48位（6个字节），前24位由IEEE（电气和电子工程师协会）决定如何分配，后24位由实际生产该网络设备的厂商自行制定。</p><p>OSI模型（Open System Interconnection ReferenceModel），是一种概念模型，是一个标准，一个试图使各种计算机在世界范围内互连为网络的标准框架。<div class="code-wrapper"><pre><code class="hljs armasm">第一层：物理层（Physical Layer），它是提供物理链路、传递电信号或光信号用的在局域网上传输比特流，它负责管理计算机通信设备和网络媒体之间的互通包括针脚、电压、线缆规范、集线器、中继器、网卡、主机接口卡等第二层：数据链路层（<span class="hljs-meta">Data</span> Link Layer），负责网络寻址、错误侦测和改错当表头和表尾被加至数据包时，会形成帧（数据帧：<span class="hljs-meta">data</span> frame）而且此层还负责MAC地址第三层：网络层（Network Layer），决定数据的路径选择（数据选路）和转寄将网络表头（NH）加至数据包，以形成分组网络表头包含了网络数据，例如：<span class="hljs-built_in">IP</span>地址第四层：传输层（Transport Layer），它会建立一个安全通道，以防数据丢失端到端之间的连接建立，把传输表头（TH）加至数据以形成数据包传输表头包含了所使用的协议等发送信息，例如：传输控制协议（TCP）第五层：会话层（Session Layer），负责在数据传输中设置和维护计算机网络中两台计算机之间的通信连接第六层：表达层（Presentation Layer），将信息数据进行加密，及数据的转化信息数据经过加密、转换、压缩，转换为能与接收者的系统格式兼容并适合传输的格式第七层：应用层（Application Layer），起调用的作用提供为应用软件而设的接口，设置与另一应用软件之间的通信例如: HTTP，HTTPS，FTP，TELNET，SSH，SMTP，POP3.HTML.等</code></pre></div></p><p>IP地址与MAC地址的区别：1、IP地址应用于OSI模型的网络层，而MAC地址应用在OSI模型的数据链路层。2、地址长度、设计理念不同、分配依据不同。3、IP地址未必都不一样，与地理区域等有关。MAC地址只和硬件设备有关。</p><p>IP地址的提出，主要是为了减少广播的数量，可以智能学习目标地址在哪个网卡。</p><p><a href="https://www.zhihu.com/question/21546408"title="有了 IP 地址，为什么还要用 MAC 地址？">点击查看详情</a></p><h3 id="存储">存储</h3><p><a href="https://zhuanlan.zhihu.com/p/166633984"title="存储技术入门详解">点击跳转：存储技术入门详解</a></p>]]></content>
    
    
    <categories>
      
      <category>Life</category>
      
    </categories>
    
    
    <tags>
      
      <tag>study</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔系列3：生活常识</title>
    <link href="/2023/11/25/Informal%20Essay%2003/"/>
    <url>/2023/11/25/Informal%20Essay%2003/</url>
    
    <content type="html"><![CDATA[<h3 id="常见亲属称谓">常见亲属称谓</h3><p>父亲的哥哥 &gt; 伯父、伯伯、大爷（~~~伯母、大娘）</p><p>父亲的弟弟 &gt; 叔叔（~~~婶婶）</p><p>父亲的姐妹 &gt; 姑姑（~~~姑父/夫）</p><p>母亲的兄弟 &gt; 舅舅（~~~舅妈）</p><p>母亲的姐妹 &gt; 姨（~~~姨夫/父）</p><p>父亲之父 &gt; 爷爷（祖父）</p><p>父亲之母 &gt; 奶奶（祖母）</p><p>母亲之父 &gt; 姥爷、外公、外爷（外祖父）</p><p>母亲之母 &gt; 姥姥、外婆（外祖母）</p><p>爷爷的姐妹 &gt; 姑奶（~~~姑爷）</p><p>爷爷的兄弟 &gt; 爷爷</p><p>奶奶的姐妹 &gt; 姨奶（~~~姨爷）</p><p>奶奶的兄弟 &gt; 舅爷（~~~舅奶）</p><h3 id="名酒记">名酒记</h3><p>中国新老八大名酒： <div class="code-wrapper"><pre><code class="hljs">茅台  汾酒  泸州老窖（特曲）古井贡酒  五粮液  董酒剑南春  洋河大曲  西凤酒</code></pre></div> 安徽酒： <div class="code-wrapper"><pre><code class="hljs">古井贡酒  口子窖  高炉家酒  文王贡酒迎驾贡酒  金种子  宣酒  皖酒  金坛子酒店小二酒  沙河王  明光酒  ···</code></pre></div></p>]]></content>
    
    
    <categories>
      
      <category>Life</category>
      
    </categories>
    
    
    <tags>
      
      <tag>common</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔系列2：省会</title>
    <link href="/2023/11/25/Informal%20Essay%2002/"/>
    <url>/2023/11/25/Informal%20Essay%2002/</url>
    
    <content type="html"><![CDATA[<h3 id="省份直辖市-简称-首都省会">省份/直辖市-简称-首都（省会）</h3><div class="code-wrapper"><pre><code class="hljs">北京市-京-北京  天津市-津-天津  上海市-沪-上海  重庆市-渝-重庆黑龙江省-黑-哈尔滨  吉林省-吉-长春  辽宁省-辽-沈阳  内蒙古自治区-蒙-呼和浩特新疆维吾尔族自治区-新-乌鲁木齐  西藏自治区-藏-拉萨  甘肃省-甘-兰州青海省-青-西宁  陕西省-陕-西安  宁夏回族自治区-宁-银川  河南省-豫-郑州河北省-冀-石家庄  安徽省-皖-合肥  山西省-晋-太原  湖南省-湘-长沙湖北省-鄂-武汉  江苏省-苏-南京  四川省-蜀-成都  贵州省-黔-贵阳云南省-云-昆明  广西壮族自治区-桂-南宁  广东省-粤-广州  山东省-鲁-济南浙江省-浙-杭州  江西省-赣-南昌  福建省-闽-福州  海南省-琼-海口香港特别行政区-港-香港  澳门特别行政区-澳-澳门  台湾省-台-台北</code></pre></div><h3 id="行政区划分">行政区划分</h3><p>省级行政区：23个省，5个自治区，4个直辖市，2个特别行政区，共计34个省级行政区。</p><p>地级行政区：地级市（含省会）、地区、自治州、盟。</p><p>县级行政区：县（包括县级市、自治县、旗、自治旗）、市辖区、特区、林区。</p><p>乡级行政区：街道办事处、镇、乡（包括民族乡、苏木）、县辖区。</p><p>村级：居民委员会、村民委员会。</p><p>PS：根据中华人民共和国宪法，人民代表大会是中国最高权利机关，各级人民代表大会选举各级人民政府作为行政机关。所以严格来说，只有拥有政府和人大的级别才算行政区划，没有的就不算。因此，地区、盟、街道办事处、村民委员会、居民委员会均不是行政区划，其中村民委员会、居民委员会是基层群众自治组织，地区、盟、街道办事处是上级政府的派出机构。相应的，地区和盟下辖的县级行政区，实际上直接属于上级行政区（省、自治区），街道办事处下辖的村委会和居委会也同样直接隶属于县、县级市、市辖区。</p><h3 id="中国地理区域">中国地理区域</h3><p>行政大区是在中国建国初期设置的，是当年位于省级之上的行政区划。当时为了便于管理，政府将全国划分为六大行政区：华北（北京）、东北（沈阳）、华东（上海）、中南（武汉）、西南（重庆）、西北（西安）。</p><p>中国七大地理区域：华东地区、华南地区、华北地区、华中地区、东北地区、西南地区、西北地区。</p><p><a href="https://zhuanlan.zhihu.com/p/107971624?utm_source=weibo"title="点击此处查看你不知道的中国各种地理区域划分！">⪧中国地理划分⪦</a></p>]]></content>
    
    
    <categories>
      
      <category>Life</category>
      
    </categories>
    
    
    <tags>
      
      <tag>common</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>随笔系列1：朝代</title>
    <link href="/2023/11/25/Informal%20Essay%2001/"/>
    <url>/2023/11/25/Informal%20Essay%2001/</url>
    
    <content type="html"><![CDATA[<h4 id="夏朝">夏朝</h4><p>大禹 ---------- 桀</p><h4 id="商朝">商朝</h4><p>成汤 ---------- 商纣王</p><h4 id="周朝">周朝</h4><p>分封诸侯，是中国历史上最长的朝代，从西周【周武王】到东周【周平王】，终于【郝王】。<div class="code-wrapper"><pre><code class="hljs">东周时期分为春秋、战国春秋五霸：齐 晋 楚 秦 宋战国七雄：秦 韩 赵 魏 楚 燕 齐诸子百家也在这一时期</code></pre></div></p><h4 id="秦国">秦国</h4><p>始皇帝：嬴政 ---------- 胡亥 <div class="code-wrapper"><pre><code class="hljs">奴隶社会的终结，封建社会的开始，提出并实行郡县制</code></pre></div></p><h5 id="楚汉之争">楚汉之争</h5><p>项羽 VS 刘邦</p><h4 id="西汉">西汉</h4><p>始于汉高祖：刘邦</p><h5 id="新朝">新朝</h5><p>王莽篡汉，成立新朝</p><h4 id="东汉">东汉</h4><p>光武帝刘秀 ---------- 汉献帝刘协</p><h4 id="三国">三国</h4><p>曹魏（曹操）、蜀汉（刘备）、孙吴（孙权）</p><h4 id="西晋">西晋</h4><p>司马炎（司马昭之子）建立</p><h5 id="东晋-五胡十六国-南北朝">东晋 五胡十六国 南北朝</h5><p>乱世时期</p><h4 id="隋朝">隋朝</h4><p>隋文帝杨坚 ---------- 隋炀帝杨广</p><h4 id="唐朝">唐朝</h4><p>唐高祖李渊 ---------- 唐景宗李柷 &gt; 开元盛世：玄宗李隆基 &gt;贞观之治：太宗李世民</p><h5 id="五代十国">五代十国</h5><p>乱世时期</p><h4 id="北宋">北宋</h4><p>宋太祖赵匡胤 ---------- 宋钦宗赵恒（宋徽宗赵佶之子）</p><h5 id="辽">辽</h5><p>实为北宋前由耶律阿保机建立</p><h5 id="金">金</h5><p>完颜阿骨打建立，灭辽、北宋，亡于南宋和蒙古</p><h4 id="南宋">南宋</h4><p>宋高宗赵构（亦为徽宗之子）建立</p><h4 id="元朝">元朝</h4><p>忽必烈建立 <div class="code-wrapper"><pre><code class="hljs">成吉思汗建立蒙古政权，算元朝的前身元朝是首次由少数民族建立的朝代</code></pre></div></p><h4 id="明朝">明朝</h4><p>明太祖朱元璋 ---------- 末代皇帝崇祯（朱由检）</p><h4 id="清朝">清朝</h4><p>由清太宗皇太极改国号为清 ———— 顺治皇帝爱新觉罗•福临一统 ————末代皇帝宣统帝（溥仪） <div class="code-wrapper"><pre><code class="hljs">努尔哈赤建立的是后金（称汗），不算清帝</code></pre></div></p>]]></content>
    
    
    <categories>
      
      <category>Life</category>
      
    </categories>
    
    
    <tags>
      
      <tag>common</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Markdown基本语法</title>
    <link href="/2023/11/24/Markdown/"/>
    <url>/2023/11/24/Markdown/</url>
    
    <content type="html"><![CDATA[<h3 id="一标题">一、标题</h3><p>在文字前加井号 # 表示标题，共支持六级标题。</p><p><strong>注：几乎所有语法符号后要跟个空格再接内容</strong></p><p>示例： <div class="code-wrapper"><pre><code class="hljs clean"># 一级标题## 二级标题### 三级标题···以此类推···</code></pre></div></p><h3 id="二文字与排版">二、文字与排版</h3><ul><li><p><strong>加粗</strong> 在两个星号 * ··· *之间写的内容会被加粗</p></li><li><p><em>斜体</em> 将要倾斜的文字前后各用两个 * 包起来</p></li><li><p><strong><em>斜体加粗</em></strong> 前后各三个 *</p></li><li><p><del>删除线</del> 前后各两个 ~</p></li></ul><p>注：以上不加空格</p><ul><li>换行 &lt;br/&gt; (&lt;br&gt;···&lt;/br&gt;)</li></ul><p>可以内嵌Html语法，例如：段落&lt;p&gt;&lt;/p&gt;(可能不加结束标签也可，但不要依赖这种做法！)、链接&lt;ahref="URL名"&gt;显示内容&lt;/a&gt;、图片&lt;img src="URL名" width="宽度"height="高度" /&gt;等</p><ul><li>引用 在引用的文字前加一个或多个 &gt; 即可</li></ul><p>效果：</p><blockquote><p>引用1</p></blockquote><blockquote><blockquote><p>引用2</p></blockquote></blockquote><ul><li>分割线 用三个及以上的 * 或 - 单独成行</li></ul><hr /><ul><li><p>列表</p><ul><li><p>无序列表 用 * 或 - 或 + 都行，后接空格</p></li><li><p>有序列表 数字加点 <div class="code-wrapper"><pre><code class="hljs markdown"><span class="hljs-bullet">1.</span> list1<span class="hljs-bullet">2.</span> list2</code></pre></div></p></li><li><p>嵌套列表 上下两级之间敲两个空格即可</p></li></ul></li><li><p>代码块 (``````)用括号中的反引号将需要标注的块区域包起来，三个就行，但是自动补全机制写六个更省事（不加括号，自成一行）</p><p>单行代码：前后各用一个 ` 就行</p><p>代码块： <div class="code-wrapper"><pre><code class="hljs">这里是代码块</code></pre></div> 单行代码： <code>这里是单行代码</code></p><p>支持语法高亮，在首行 ` 后紧跟着写相应语言即可，如python</p></li><li><p>脚注用方括号[]和^可以构成一个脚注，可在后方写注释，注释显示在文末</p><p>脚注写法：[^1] <br/> 注释写法：[^1]: Content</p><p>效果：脚注<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><spanclass="hint--top hint--rounded"aria-label="这是一个脚注^_^">[1]</span></a></sup></p></li></ul><h3 id="三插入超链接和图片">三、插入超链接和图片</h3><ol type="1"><li><p>[超链接名] (超链接地址 "超链接title") 示例：[百度](http://baidu.com)</p></li><li><p>![图片名] (图片地址 "图片title") 图片名为下标</p></li><li><p><URL名> 可点击的链接，也可填入Email地址</p></li></ol><p>注：名和地址之间中间不加空格，title可不加<br>title与地址间空一格，内容在鼠标悬停于超链接或图片上时显示</br></p><h3 id="四表格">四、表格</h3><p>用管道符 | 来分隔各列，用 ------ (多个) 来创建（隔开）表头。</p><p>示例： <div class="code-wrapper"><pre><code class="hljs gherkin">|<span class="hljs-string"> theHead1 </span>|<span class="hljs-string"> theHead2 </span>|<span class="hljs-string"> theHead3 </span>|<span class="hljs-string"> theHead4 </span>||<span class="hljs-string"> -------- </span>|<span class="hljs-string"> :------- </span>|<span class="hljs-string"> -------: </span>|<span class="hljs-string"> :------: </span>||<span class="hljs-string"> 内容1 </span>|<span class="hljs-string"> 内容2 </span>|<span class="hljs-string"> 内容3 </span>|<span class="hljs-string"> 内容4 </span>||<span class="hljs-string"> 内容1 </span>|<span class="hljs-string"> 内容2 </span>|<span class="hljs-string"> 内容3 </span>|<span class="hljs-string"> 内容4 </span>|</code></pre></div></p><table><thead><tr class="header"><th>theLongHead1</th><th style="text-align: left;">theLongHead2</th><th style="text-align: right;">theLongHead3</th><th style="text-align: center;">theLongHead4</th></tr></thead><tbody><tr class="odd"><td>内容1</td><td style="text-align: left;">内容2</td><td style="text-align: right;">内容3</td><td style="text-align: center;">内容4</td></tr><tr class="even"><td>内容1</td><td style="text-align: left;">内容2</td><td style="text-align: right;">内容3</td><td style="text-align: center;">内容4</td></tr></tbody></table><table><thead><tr class="header"><th>1</th><th style="text-align: left;">2</th><th style="text-align: right;">3</th><th style="text-align: center;">4</th></tr></thead><tbody><tr class="odd"><td>超长的内容1</td><td style="text-align: left;">超长的内容2</td><td style="text-align: right;">超长的内容3</td><td style="text-align: center;">超长的内容4</td></tr><tr class="even"><td>超长的内容1</td><td style="text-align: left;">超长的内容2</td><td style="text-align: right;">超长的内容3</td><td style="text-align: center;">超长的内容4</td></tr></tbody></table><p>在分隔行的连字符 - 左侧、右侧或两侧可以加冒号 :使得该列内容左对齐、右对齐或居中显示，默认（不加冒号时）左对齐。</p><h3 id="扩展语法">扩展语法</h3><h4 id="任务列表语法">任务列表语法</h4><p>短横杠 - 加方括号 [ ] （都有空格） <br/> 选择（复选框）则用 x替换方括号中的空格：[x]</p><p>效果：</p><ul class="task-list"><li><label><input type="checkbox"checked="" />这是一个复选框</label></li><li><label><input type="checkbox" />这是一个普通任务项</label></li></ul><h4 id="注意事项">注意事项</h4><p>使用hexo-renderer-pandoc渲染器，卸载了hexo自带的marked渲染器后，有些Markdown语法格式与LaTex语法格式冲突，因此需要注意以下几点：</p><ol type="1"><li>不要在代码块(`划定的区域)中插入公式，会无法解析/渲染</li><li>引用&gt;时，或者用其他符号如任务列表语法-[]、标题#时，最好单独成行，前、后各空一行，LaTex对“吃”空格/行</li><li>使用公式要在Front-matter中指定："math: true"</li><li>有脚注时，要在文末空个两行，防止脚注紧贴正文，正文格式会影响脚注的显示格式</li><li>空一行及以上，渲染结果就是内容之间间隔一行；换行渲染后仅相当于空格；可用&lt;br/&gt;来换行</li></ol><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>这是一个脚注^_^<a href="#fnref:1" rev="footnote" class="footnote-backref">↩︎</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>auxiliary</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2023/11/24/HelloWorld/"/>
    <url>/2023/11/24/HelloWorld/</url>
    
    <content type="html"><![CDATA[<p>This is my first article.</p><p>In order to create my own blog, I studied for several days, andfinally achieved initial results.</p><hr /><p>I've been studying for days to create a blog of my own, and I'mfinally getting there.</p><p>This shows that it is very important to learn English well.</p>]]></content>
    
    
    <categories>
      
      <category>Default</category>
      
    </categories>
    
    
    <tags>
      
      <tag>foreword</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
