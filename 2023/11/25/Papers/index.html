

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=light>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/planet.png">
  <link rel="icon" href="/img/planet.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Zenitsu">
  <meta name="keywords" content="">
  
    <meta name="description" content="TarDAL Title Target-aware Dual Adversarial Learning and a Multi-scenario Multi-modality Benchmark to Fuse Infrared and Visible for Object Detection [CVPR] 2022 Motivation Previous approaches: 1">
<meta property="og:type" content="article">
<meta property="og:title" content="文献整理 · 开山篇">
<meta property="og:url" content="https://afly36-swordsman.github.io/2023/11/25/Papers/index.html">
<meta property="og:site_name" content="Mark | Learning &amp; Routine">
<meta property="og:description" content="TarDAL Title Target-aware Dual Adversarial Learning and a Multi-scenario Multi-modality Benchmark to Fuse Infrared and Visible for Object Detection [CVPR] 2022 Motivation Previous approaches: 1">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/11.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/12.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/13.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/14.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/15.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/16.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/21.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/22.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/23.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/24.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/25.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/26.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/31.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/32.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/33.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/34.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/36.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/35.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/37.png">
<meta property="article:published_time" content="2023-11-25T15:43:58.212Z">
<meta property="article:modified_time" content="2024-05-12T06:20:41.576Z">
<meta property="article:author" content="Zenitsu">
<meta property="article:tag" content="summarize">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://afly36-swordsman.github.io/img/stage1/11.png">
  
  
  
  <title>文献整理 · 开山篇 - Mark | Learning &amp; Routine</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"afly36-swordsman.github.io","root":"/","version":"1.9.5","typing":{"enable":true,"typeSpeed":40,"cursorChar":"✨","loop":false,"scope":["home"]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"left","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":1},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>M.E.Mark&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/taiji.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">文献整理 · 开山篇</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-11-25 23:43" pubdate>
          2023.11.25 23:43
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          7.7k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          10 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="padding-left: 2rem; margin-right: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">文献整理 · 开山篇</h1>
            
              <p class="note note-info">
                
                  
                    Last updated on May 12, 2024 pm
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h2 id="tardal">TarDAL</h2>
<h3 id="title">Title</h3>
<p>Target-aware Dual Adversarial Learning and a Multi-scenario
Multi-modality Benchmark to Fuse Infrared and Visible for Object
Detection [CVPR] 2022</p>
<h3 id="motivation">Motivation</h3>
<p>Previous approaches:</p>
<div class="code-wrapper"><pre><code class="hljs mipsasm"><span class="hljs-number">1</span>.Aiming <span class="hljs-built_in">at</span> generating an image of high visual quality

<span class="hljs-number">2</span>.<span class="hljs-keyword">Discover </span>commons underlying the two modalities <span class="hljs-keyword">and </span>fuse
upon the common space <span class="hljs-keyword">either </span><span class="hljs-keyword">by </span>iterative optimization <span class="hljs-keyword">or </span>deep networks

<span class="hljs-number">3</span>.Neglect that modality <span class="hljs-keyword">differences </span>implying the complementary infomation
which <span class="hljs-keyword">extremely </span>important for <span class="hljs-keyword">both </span>fusion <span class="hljs-keyword">and </span><span class="hljs-keyword">subsequent </span>detection task</code></pre></div>
<h3 id="intro">Intro</h3>
<div class="code-wrapper"><pre><code class="hljs maxima">Visible <span class="hljs-built_in">image</span>, provides rich details with high spatial <span class="hljs-built_in">resolution</span>
(under welldefined lighting conditions)</code></pre></div>
<div class="code-wrapper"><pre><code class="hljs sqf">Infrared <span class="hljs-built_in">image</span>, capturing ambient temperature variations emitted <span class="hljs-keyword">from</span> objects, 
highlight structures of thermal <span class="hljs-built_in">targets</span> (insensive <span class="hljs-keyword">to</span> lighting changes)</code></pre></div>
<p>Their evident appearance discrepancy, it's challenging to fuse
visually appealing images and/or to support higher-level vision tasks
(by making full use of the complementary info from the infrared and
visible images)</p>
<p>The fusion emphasizes more on "seeking commons" but neglect the
differences of these two modalities on presenting structure info of
targets and textural details of ambient background.</p>
<h3 id="method">Method</h3>
<p>Fusion network:</p>
<div class="code-wrapper"><pre><code class="hljs mipsasm">Composed of one generator <span class="hljs-keyword">and </span>two target-aware <span class="hljs-keyword">discriminators, </span>
<span class="hljs-keyword">and </span>a commonly used detection network  [Detection-<span class="hljs-keyword">oriented </span>fusion]
<span class="hljs-symbol"></span>
<span class="hljs-symbol">Discriminator:</span>
<span class="hljs-keyword">Distinguishes </span>foreground(structure infomation of targets), 
i.e., thermal targets(infrared image), <span class="hljs-keyword">and </span><span class="hljs-keyword">differentiates</span>
<span class="hljs-keyword"></span>the <span class="hljs-keyword">background, </span>i.e., textural details(visible image)

Derive a cooperative training <span class="hljs-keyword">scheme</span></code></pre></div>
<h3 id="structure-diagram">Structure diagram</h3>
<figure>
<img src="/img/stage1/11.png" srcset="/img/loading.gif" lazyload
alt="Methodology framework: (a) bilevel optimization formulation for fusion and detection, (b) target-aware adversarial dual learning network for fusion, and (c) cooperative training scheme." />
<figcaption aria-hidden="true">Methodology framework: (a) bilevel
optimization formulation for fusion and detection, (b) target-aware
adversarial dual learning network for fusion, and (c) cooperative
training scheme.</figcaption>
</figure>
<figure>
<img src="/img/stage1/12.png" srcset="/img/loading.gif" lazyload alt="The details of network" />
<figcaption aria-hidden="true">The details of network</figcaption>
</figure>
<figure>
<img src="/img/stage1/13.png" srcset="/img/loading.gif" lazyload
alt="The architectures of generator and discriminator" />
<figcaption aria-hidden="true">The architectures of generator and
discriminator</figcaption>
</figure>
<h3 id="loss-function">Loss function</h3>
<p>Detection network backbone: YOLOv5</p>
<p>Generator: 1.Structural similarity index (SSIM)</p>
<blockquote>
<p>Contributes to generate a fused image that preserves overall
structures and maintains a similar intensity distribution as source
images.</p>
</blockquote>
<figure>
<img src="/img/stage1/14.png" srcset="/img/loading.gif" lazyload alt="Generator loss SSIM" />
<figcaption aria-hidden="true">Generator loss SSIM</figcaption>
</figure>
<p>2.Pixel loss (based on the saliency degree weight (SDW))</p>
<blockquote>
<p>To balance the pixel intensity distribution of source images</p>
</blockquote>
<p><img src="/img/stage1/15.png" srcset="/img/loading.gif" lazyload alt="Pixel Loss" /> w1, w2 are
calculated by saliency value of x and y.</p>
<p>Target and detail discriminators: Wasserstein divergence (with target
mask m)</p>
<blockquote>
<p>The target discriminator <span class="math inline">\(D_T\)</span> is
used to distinguish the foreground thermal targets of fused result to
the infrared while the detail discriminator <span
class="math inline">\(D_D\)</span> contributes to distinguish the
background details of fused result to the visible.</p>
</blockquote>
<figure>
<img src="/img/stage1/16.png" srcset="/img/loading.gif" lazyload alt="Discriminator loss" />
<figcaption aria-hidden="true">Discriminator loss</figcaption>
</figure>
<h2 id="seafusion">SeAFusion</h2>
<h3 id="title-1">Title</h3>
<p>Image fusion in the loop of high-level vision tasks: A semantic-aware
real-time infrared and visible image fusion network [Image Fusion]
2022</p>
<h3 id="intro-1">Intro</h3>
<p>The infrared sensor captures thermal radiation emitted from objects,
which could highlight salient targets, but the infrared image neglects
texture and is vulnerable to noise.</p>
<p>The visible sensor captures reflective light infomation, the visible
image usually contains abundant texture and structure info, but is
sensitive to the environment, such as illumination and occlusion.</p>
<p>Complementary info: to fuse Ir and Vis image, to generate a desired
image.</p>
<p>Fused image has been broadly used as a preprocessing module for
high-level vision tasks, e.g., object detection, tracking, semantic
segmentation.</p>
<h3 id="motivation-1">Motivation</h3>
<p>Pressing challenges:</p>
<div class="code-wrapper"><pre><code class="hljs livecodeserver"><span class="hljs-number">1.</span>The existing fusion algorithms are inclined <span class="hljs-built_in">to</span> pursue better visual quality
<span class="hljs-keyword">and</span> higher evaluation metrics but seldom systematically consider
whether fused image can facilitate high-level vision tasks

Some studies: cannot effectively enhance/boost <span class="hljs-keyword">the</span> semantic info <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> fused image

<span class="hljs-number">2.</span>Neither visual comparison nor quantitative evaluation (evaluation manners)
reflects <span class="hljs-keyword">the</span> facilitation <span class="hljs-keyword">of</span> fused images <span class="hljs-keyword">for</span> high-level vision tasks

<span class="hljs-number">3.</span>Not <span class="hljs-keyword">effective</span> <span class="hljs-keyword">in</span> extracting fine-grained detail features

<span class="hljs-number">4.</span>Ignore <span class="hljs-keyword">the</span> demand <span class="hljs-keyword">for</span> real-<span class="hljs-built_in">time</span> image fusion</code></pre></div>
<p>Ours network:</p>
<p>SeAFusion, can be used for achieving real-time Ir &amp; Vis image
fusion</p>
<h3 id="method-1">Method</h3>
<div class="code-wrapper"><pre><code class="hljs pgsql"><span class="hljs-number">1.</span>Simultaneously obtaining superior performance <span class="hljs-keyword">in</span>
<span class="hljs-keyword">both</span> image fusion <span class="hljs-keyword">and</span> high-<span class="hljs-keyword">level</span> vision tasks.

<span class="hljs-number">2.</span>A segmentation network <span class="hljs-keyword">to</span> predict the segmentation results
<span class="hljs-keyword">on</span> fused images, which <span class="hljs-keyword">is</span> utilized <span class="hljs-keyword">to</span> construct semantic loss
(<span class="hljs-keyword">is</span> leveraged <span class="hljs-keyword">to</span> guide the training <span class="hljs-keyword">of</span> the fusion network via back-propagation, 
so the loss can flow back <span class="hljs-keyword">to</span> the image fusion module
<span class="hljs-keyword">to</span> forcing fused images <span class="hljs-keyword">to</span> contain more semantic infomation).

<span class="hljs-number">3.</span><span class="hljs-type">Real</span>-<span class="hljs-type">time</span>: light-weight network based <span class="hljs-keyword">on</span> GRDB (gradient residual dense block)
<span class="hljs-keyword">to</span> boost the description ability <span class="hljs-keyword">for</span> fine-grained details <span class="hljs-keyword">and</span> achieve feature reuse.

<span class="hljs-number">4.</span>The authors proposed a joint low-<span class="hljs-keyword">level</span> <span class="hljs-keyword">and</span> high-<span class="hljs-keyword">level</span> adaptive training strategy
<span class="hljs-keyword">to</span> achieve simultaneously impressive performance <span class="hljs-keyword">in</span> <span class="hljs-keyword">both</span>
image fusion <span class="hljs-keyword">and</span> various high-<span class="hljs-keyword">level</span> vision tasks.</code></pre></div>
<h3 id="structure-diagram-1">Structure diagram</h3>
<figure>
<img src="/img/stage1/21.png" srcset="/img/loading.gif" lazyload
alt="The overall framework of the proposed semantic-aware infrared and visible image fusion algorithm." />
<figcaption aria-hidden="true">The overall framework of the proposed
semantic-aware infrared and visible image fusion algorithm.</figcaption>
</figure>
<figure>
<img src="/img/stage1/22.png" srcset="/img/loading.gif" lazyload
alt="The architecture of the real-time infrared and visible image fusion network based on gradient residual dense block." />
<figcaption aria-hidden="true">The architecture of the real-time
infrared and visible image fusion network based on gradient residual
dense block.</figcaption>
</figure>
<figure>
<img src="/img/stage1/23.png" srcset="/img/loading.gif" lazyload
alt="The specific devise of the gradient residual dense block. The Sobel operator is selected as the Gradient Operator to extract fine-grained detail information of feature maps." />
<figcaption aria-hidden="true">The specific devise of the gradient
residual dense block. The Sobel operator is selected as the Gradient
Operator to extract fine-grained detail information of feature
maps.</figcaption>
</figure>
<h3 id="分析">分析</h3>
<figure>
<img src="/img/stage1/24.png" srcset="/img/loading.gif" lazyload alt="Analysis1: fusion network" />
<figcaption aria-hidden="true">Analysis1: fusion network</figcaption>
</figure>
<figure>
<img src="/img/stage1/25.png" srcset="/img/loading.gif" lazyload alt="Analysis2: segmentation module" />
<figcaption aria-hidden="true">Analysis2: segmentation
module</figcaption>
</figure>
<figure>
<img src="/img/stage1/26.png" srcset="/img/loading.gif" lazyload alt="Algorithm" />
<figcaption aria-hidden="true">Algorithm</figcaption>
</figure>
<p>注：分割网络的backbone采用YOLOv5网络</p>
<h2 id="segmif">SegMiF</h2>
<h3 id="title-2">Title</h3>
<p>Multi-interactive Feature Learning and a Full-time Multi-modality
Benchmark for Image Fusion and Segmentation [ICCV] 2023</p>
<h3 id="abstract">Abstract</h3>
<p>Early efforts boost performance for only one task.</p>
<p>This paper, SegMiF can dual-task correlation to promote the
performance of both tasks (fusion and segmentation).</p>
<h3 id="intro-2">Intro</h3>
<p>Contributions:</p>
<div class="code-wrapper"><pre><code class="hljs sql"><span class="hljs-number">1.</span>SegMiF <span class="hljs-keyword">contains</span> two modules, i.e., <span class="hljs-keyword">fusion</span> network
<span class="hljs-keyword">and</span> common segmentation network.

<span class="hljs-number">2.</span>Hierarchical interactive attention (HIA) block. 
Fine<span class="hljs-operator">-</span>grained mapping <span class="hljs-keyword">of</span> <span class="hljs-keyword">all</span> the vital infomation <span class="hljs-keyword">between</span> <span class="hljs-keyword">fusion</span> <span class="hljs-keyword">and</span> segmentation. 
Modality<span class="hljs-operator">-</span><span class="hljs-operator">/</span>Semantic<span class="hljs-operator">-</span> oriented features can be fully mutual<span class="hljs-operator">-</span>interactive
(bridge the feature gap <span class="hljs-keyword">between</span> <span class="hljs-keyword">fusion</span> <span class="hljs-keyword">and</span> segmentation).

<span class="hljs-number">3.</span><span class="hljs-keyword">Dynamic</span> weight factor, automatically adjust the <span class="hljs-keyword">corresponding</span> weights
<span class="hljs-keyword">of</span> <span class="hljs-keyword">each</span> task (optimal parameters).

<span class="hljs-number">4.</span>Interactive feature training scheme.

<span class="hljs-number">5.</span>Construct an imaging <span class="hljs-keyword">system</span> (benchmark).</code></pre></div>
<h3 id="structure-diagram-2">Structure diagram</h3>
<figure>
<img src="/img/stage1/31.png" srcset="/img/loading.gif" lazyload
alt="Workflow of the proposed SegMiF. The left part depicts the latent interactive relationship between image fusion and segmentation. The middle part plots the concrete architecture of the SegMiF. The right part details the components of proposed hierarchical interactive attention." />
<figcaption aria-hidden="true">Workflow of the proposed SegMiF. The left
part depicts the latent interactive relationship between image fusion
and segmentation. The middle part plots the concrete architecture of the
SegMiF. The right part details the components of proposed hierarchical
interactive attention.</figcaption>
</figure>
<figure>
<img src="/img/stage1/32.png" srcset="/img/loading.gif" lazyload alt="Partial zoom" />
<figcaption aria-hidden="true">Partial zoom</figcaption>
</figure>
<h3 id="分析-1">分析</h3>
<figure>
<img src="/img/stage1/33.png" srcset="/img/loading.gif" lazyload alt="Fusion network and DRDB module" />
<figcaption aria-hidden="true">Fusion network and DRDB
module</figcaption>
</figure>
<p><img src="/img/stage1/34.png" srcset="/img/loading.gif" lazyload
alt="Detailed architectures of SoAM and MoAM" />
注：分割网络是论文[SegFormer: Simple and Efficient Design for Semantic
Segmentation with Transformers]的内容</p>
<p>分割网络： <img src="/img/stage1/36.png" srcset="/img/loading.gif" lazyload
alt="Segmentation network" /></p>
<h4 id="hia">HIA</h4>
<p>1.SoAM (Semantic-oriented attention module)</p>
<blockquote>
<p>SoAM utilizes the token <span
class="math inline">\(F_{seg}^{s}\)</span> to generate the query <span
class="math inline">\(Q_s\)</span>, which represents the inhere semantic
information that needs to be enhanced.</p>
</blockquote>
<blockquote>
<p>The global context representation of each can be calculated by as
<span class="math inline">\(K_{ir}^{T}\cdot V_{ir} (G_{ir})\)</span> and
<span class="math inline">\(K_{vis}^{T}\cdot V_{vis} (G_{vis})\)</span>
, 其中K, V ∈ {<span class="math inline">\(F_{ir}^{s}\)</span>, <span
class="math inline">\(F_{vis}^{s}\)</span>}</p>
</blockquote>
<p><span class="math inline">\(S_{ir} = Q_s\cdot G_{ir}\)</span>, <span
class="math inline">\(S_{vis} = Q_s\cdot G_{vis}\)</span></p>
<blockquote>
<p>SoAM to provide more semantic attention for the modality feature.</p>
</blockquote>
<p>2.MoAM (Modality-oriented attention module)</p>
<blockquote>
<p>MoAM introduce two modality queries <span
class="math inline">\(Q_{ir}\)</span> and <span
class="math inline">\(Q_{vis}\)</span> ∈ {<span
class="math inline">\(F_{ir}^{m}\)</span>, <span
class="math inline">\(F_{vis}^{m}\)</span>}</p>
</blockquote>
<blockquote>
<p>The global context of segmentation <span
class="math inline">\(G_s\)</span> by <span
class="math inline">\(K_{s}^{T}\cdot V_s\)</span></p>
</blockquote>
<p><span class="math inline">\(M_{ir} = Q_{ir}\cdot G_s\)</span>, <span
class="math inline">\(M_{vis} = Q_{vis}\cdot G_s\)</span></p>
<blockquote>
<p>MoAM to investigate the significant feature from semantic
contexts.</p>
</blockquote>
<h4 id="目标函数">目标函数</h4>
<figure>
<img src="/img/stage1/35.png" srcset="/img/loading.gif" lazyload alt="Joint formulation" />
<figcaption aria-hidden="true">Joint formulation</figcaption>
</figure>
<p>损失函数： <img src="/img/stage1/37.png" srcset="/img/loading.gif" lazyload alt="Loss" /></p>
<div class="code-wrapper"><pre><code class="hljs armasm">损失函数中涉及了两个常用的概念：
结构相似度、显著性图

<span class="hljs-number">1</span>.结构相似度SSIM主要用来衡量两幅图亮度、对比度和结构的相似性
  详见<span class="hljs-string">&quot;专业笔记&quot;</span>中所述

<span class="hljs-number">2</span>.显著性图主要用来计算MSE损失中的显著性参数m
  源自论文: Infrared <span class="hljs-keyword">and</span> visible image fusion based on visual saliency <span class="hljs-meta">map</span>
            <span class="hljs-keyword">and</span> weighted least square optimization</code></pre></div>
<h2 id="相关内容">相关内容</h2>
<div class="code-wrapper"><pre><code class="hljs mathematica">当<span class="hljs-variable">CNN</span>层数变深时，输出到输入的路径就会变得很长。
梯度反向传播，到达输入层可能就会消失。
<span class="hljs-variable">DenseNet</span>是一种深度卷积神经网络，引入密集连接（<span class="hljs-variable">Dense</span> <span class="hljs-variable">Connection</span>）将前面所有层与后面的层建立密集连接。
与<span class="hljs-variable">ResNet</span>的关键区别是，<span class="hljs-variable">ResNet</span>是简单相加，<span class="hljs-variable">DenseNet</span>是进行连接。
<span class="hljs-variable">DenseNet</span>通过基本构建单元<span class="hljs-variable">Dense</span> <span class="hljs-built_in">Block</span>实现稠密连接对特征进行重用，实现信息共享，并能增强梯度流动，避免梯度消失。
过渡层（<span class="hljs-variable">Transition</span> <span class="hljs-variable">Layer</span>）控制通道数（稠密块会带来通道数的增加），防止模型过于复杂。
<span class="hljs-variable">DenseNet</span>在模型精度和泛化能力上通常表现优异，训练更稳定，但结构仍比较复杂，需要消耗较多的计算资源和时间，内存占用大。

<span class="hljs-variable">ResNet</span>（<span class="hljs-variable">Residual</span> <span class="hljs-variable">Neural</span> <span class="hljs-variable">Network</span>）是基于残差学习框架的神经网络，其在前向网络中增加了一些快捷连接
<span class="hljs-variable">Shortcut</span><span class="hljs-punctuation">(</span><span class="hljs-built_in">Short</span><span class="hljs-punctuation">)</span> <span class="hljs-variable">Connection</span><span class="hljs-operator">/</span><span class="hljs-built_in">Skip</span> <span class="hljs-variable">Connection</span>，这些连接会跳过某些层，将数据直接传到之后的层。
<span class="hljs-variable">ResNet</span>对网络深度增加带来的梯度消失或爆炸、网络退化（由于训练和测试误差的积累导致正确率趋于饱和甚至下降，
与过拟合（训练误差小，测试误差大，泛化能力差）不同）等问题具有一定的作用，增加了非线性，
一定程度上抑制了语义间隙的影响，但模型表现可能略逊一筹。
残差块（<span class="hljs-variable">Residual</span> <span class="hljs-built_in">Block</span>）是<span class="hljs-variable">ResNet</span>的基本组成成分。</code></pre></div>
<div class="code-wrapper"><pre><code class="hljs arcade">空洞卷积（Dilated/Atrous Convolution）可以增加卷积核的尺寸，如原本<span class="hljs-number">3</span>*<span class="hljs-number">3</span>的卷积核可以扩充至<span class="hljs-number">5</span>*<span class="hljs-number">5</span>，
但有效的参数个数不变，仍为<span class="hljs-number">9</span>个，剩余的位置不予考虑（空洞/零），利用超参数“扩张率”来定义卷积核处理数据时各值的间距
（可以理解为空洞数），在扩大了感受野的同时，避免了Pooling操作，从而保持分辨率不变。
PS：正常扩大感受野会带来计算量的增加，后面进行池化的降采样处理可以降低计算量，但是空间分辨率也随之降低了。

感受野（Receptive Field）越大，捕获的图像区域越大，对图像全局的特征提取能力也就越强。
而且对于目标检测任务而言，最后一层特征图（<span class="hljs-built_in">Feature</span> <span class="hljs-built_in">Map</span>）的感受野大小要大于等于输入图像大小，否则分类性能会不理想。
一般而言，感受野越大、网络越深，对复杂问题求解的模型性能越好。</code></pre></div>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Learning/" class="category-chain-item">Learning</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/summarize/" class="print-no-link">#summarize</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>文献整理 · 开山篇</div>
      <div>https://afly36-swordsman.github.io/2023/11/25/Papers/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Zenitsu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>November 25, 2023</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Updated on</div>
          <div>May 12, 2024</div>
        </div>
      
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2023/12/16/Review/" title="图像融合">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">图像融合</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/11/25/Professional/" title="专业笔记">
                        <span class="hidden-mobile">专业笔记</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar category-bar" style="margin-left: -1rem">
    





<div class="category-list">
  
  
    
    
    
    <div class="category row nomargin-x">
      <a class="category-item 
          list-group-item category-item-action col-10 col-md-11 col-xm-11" title="Learning"
        id="heading-8af0f5c3edad8d8e158ff27b9f03afac" role="tab" data-toggle="collapse" href="#collapse-8af0f5c3edad8d8e158ff27b9f03afac"
        aria-expanded="true"
      >
        Learning
        <span class="list-group-count">(11)</span>
        <i class="iconfont icon-arrowright"></i>
      </a>
      
      <div class="category-collapse collapse show" id="collapse-8af0f5c3edad8d8e158ff27b9f03afac"
           role="tabpanel" aria-labelledby="heading-8af0f5c3edad8d8e158ff27b9f03afac">
        
        
          
  <div class="category-post-list">
    
    
      
      
        <a href="/2024/03/14/knowledge/" title="Knowledge Mining"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Knowledge Mining</span>
        </a>
      
    
      
      
        <a href="/2023/11/24/Markdown/" title="Markdown基本语法"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">Markdown基本语法</span>
        </a>
      
    
      
      
        <a href="/2023/11/25/Professional/" title="专业笔记"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">专业笔记</span>
        </a>
      
    
      
      
        <a href="/2024/01/20/Conference/" title="会议和期刊"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">会议和期刊</span>
        </a>
      
    
      
      
        <a href="/2023/12/16/Review/" title="图像融合"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">图像融合</span>
        </a>
      
    
      
      
        <a href="/2023/11/25/Papers/" title="文献整理 · 开山篇"
           class="list-group-item list-group-item-action
           active">
          <span class="category-post">文献整理 · 开山篇</span>
        </a>
      
    
      
      
        <a href="/2024/03/14/papers5/" title="文献整理 · 旁搜博采篇"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">文献整理 · 旁搜博采篇</span>
        </a>
      
    
      
      
        <a href="/2023/12/20/papers4/" title="文献整理 · 海纳百川篇"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">文献整理 · 海纳百川篇</span>
        </a>
      
    
      
      
        <a href="/2023/12/20/papers2/" title="文献整理 · 脉络篇（一）"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">文献整理 · 脉络篇（一）</span>
        </a>
      
    
      
      
        <a href="/2023/12/20/papers3/" title="文献整理 · 脉络篇（二）"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">文献整理 · 脉络篇（二）</span>
        </a>
      
    
      
      
        <a href="/2023/12/21/Computer/" title="随笔系列6：计算机基础"
           class="list-group-item list-group-item-action
           ">
          <span class="category-post">随笔系列6：计算机基础</span>
        </a>
      
    
  </div>

        
      </div>
    </div>
  
</div>


  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">

  <div>
    <span id="timeDate">正在载入天数...</span>
    <span id="times">载入时分秒...</span>
    <script>
    var now = new Date();
    function createtime(){
        var grt= new Date("11/24/2023 11:30:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24;
        dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);
        hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){
            hnum = "0" + hnum;
        }
        minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes);
        if(String(mnum).length ==1 ){
                  mnum = "0" + mnum;
        }
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds);
        if(String(snum).length ==1 ){
                  snum = "0" + snum;
        }
        document.getElementById("timeDate").innerHTML = "🚀 for&nbsp"+dnum+"&nbspdays";  
        document.getElementById("times").innerHTML = hnum + "&nbsphr&nbsp" + mnum + "&nbspmin&nbsp" + snum + "&nbspsec";
    }
    setInterval("createtime()",250);
    </script>
  </div>  

  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  

</div>
  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>




  
<script src="/js/custom.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>

</body>
</html>
