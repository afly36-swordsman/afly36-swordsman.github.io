

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/planet.png">
  <link rel="icon" href="/img/planet.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Zenitsu">
  <meta name="keywords" content="">
  
    <meta name="description" content="TarDALTitleTarget-aware Dual Adversarial Learning and a Multi-scenario Multi-modality Benchmark to Fuse Infrared and Visible for Object Detection [CVPR]  MotivationPrevious approaches: 1.Aiming at gen">
<meta property="og:type" content="article">
<meta property="og:title" content="文献整理">
<meta property="og:url" content="https://afly36-swordsman.github.io/2023/11/25/Papers/index.html">
<meta property="og:site_name" content="Mark&#39;s blog">
<meta property="og:description" content="TarDALTitleTarget-aware Dual Adversarial Learning and a Multi-scenario Multi-modality Benchmark to Fuse Infrared and Visible for Object Detection [CVPR]  MotivationPrevious approaches: 1.Aiming at gen">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/11.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/12.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/13.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/14.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/15.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/16.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/21.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/22.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/23.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/24.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/25.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/26.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/31.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/32.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/33.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/34.png">
<meta property="og:image" content="https://afly36-swordsman.github.io/img/stage1/35.png">
<meta property="article:published_time" content="2023-11-25T15:43:58.212Z">
<meta property="article:modified_time" content="2023-11-28T03:37:25.672Z">
<meta property="article:author" content="Zenitsu">
<meta property="article:tag" content="summarize">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://afly36-swordsman.github.io/img/stage1/11.png">
  
  
  
  <title>文献整理 - Mark&#39;s blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"afly36-swordsman.github.io","root":"/","version":"1.9.5","typing":{"enable":true,"typeSpeed":40,"cursorChar":"✏️","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"left","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>M.E.Mark</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/taiji.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="文献整理"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2023-11-25 23:43" pubdate>
          2023.11.25 23:43
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          5.3k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          45 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="padding-left: 2rem; margin-right: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">文献整理</h1>
            
              <p class="note note-info">
                
                  
                    Last updated on November 28, 2023 am
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h2 id="TarDAL"><a href="#TarDAL" class="headerlink" title="TarDAL"></a>TarDAL</h2><h3 id="Title"><a href="#Title" class="headerlink" title="Title"></a>Title</h3><p>Target-aware Dual Adversarial Learning and a Multi-scenario Multi-modality Benchmark to Fuse Infrared and Visible for Object Detection [CVPR] </p>
<h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><p>Previous approaches:</p>
<div class="code-wrapper"><pre><code class="hljs mipsasm"><span class="hljs-number">1</span>.Aiming <span class="hljs-built_in">at</span> generating an image of high visual quality

<span class="hljs-number">2</span>.<span class="hljs-keyword">Discover </span>commons underlying the two modalities <span class="hljs-keyword">and </span>fuse
upon the common space <span class="hljs-keyword">either </span><span class="hljs-keyword">by </span>iterative optimization <span class="hljs-keyword">or </span>deep networks

<span class="hljs-number">3</span>.Neglect that modality <span class="hljs-keyword">differences </span>implying the complementary infomation
which <span class="hljs-keyword">extremely </span>important for <span class="hljs-keyword">both </span>fusion <span class="hljs-keyword">and </span><span class="hljs-keyword">subsequent </span>detection task</code></pre></div>

<h3 id="Info"><a href="#Info" class="headerlink" title="Info"></a>Info</h3><div class="code-wrapper"><pre><code class="hljs maxima">Visible <span class="hljs-built_in">image</span>, provides rich details with high spatial <span class="hljs-built_in">resolution</span>
(under welldefined lighting conditions)</code></pre></div>
<div class="code-wrapper"><pre><code class="hljs sqf">Infrared <span class="hljs-built_in">image</span>, capturing ambient temperature variations emitted <span class="hljs-keyword">from</span> objects, 
highlight structures of thermal <span class="hljs-built_in">targets</span> (insensive <span class="hljs-keyword">to</span> lighting changes)</code></pre></div>
<p>Their evident appearance discrepancy, it’s challenging to fuse visually appealing images and&#x2F;or to support higher-level vision tasks (by making full use of the complementary info from the infrared and visible images)</p>
<p>The fusion emphasizes more on “seeking commons” but neglect the differences of these two modalities on presenting structure info of targets and textural details of ambient background.</p>
<h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p>Fusion network: </p>
<div class="code-wrapper"><pre><code class="hljs mipsasm">Composed of one generator <span class="hljs-keyword">and </span>two target-aware <span class="hljs-keyword">discriminators, </span>
<span class="hljs-keyword">and </span>a commonly used detection network  [Detection-<span class="hljs-keyword">oriented </span>fusion]
<span class="hljs-symbol"></span>
<span class="hljs-symbol">Discriminator:</span>
<span class="hljs-keyword">Distinguishes </span>foreground(structure infomation of targets), 
i.e., thermal targets(infrared image), <span class="hljs-keyword">and </span><span class="hljs-keyword">differentiates</span>
<span class="hljs-keyword"></span>the <span class="hljs-keyword">background, </span>i.e., textural details(visible image)

Derive a cooperative training <span class="hljs-keyword">scheme</span></code></pre></div>

<h3 id="Structure-diagram"><a href="#Structure-diagram" class="headerlink" title="Structure diagram"></a>Structure diagram</h3><p><img src="/img/stage1/11.png" srcset="/img/loading.gif" lazyload alt="Methodology framework: (a) bilevel optimization formulation for fusion and detection, (b) target-aware adversarial dual learning network for fusion, and (c) cooperative training scheme."></p>
<p><img src="/img/stage1/12.png" srcset="/img/loading.gif" lazyload alt="The details of network"></p>
<p><img src="/img/stage1/13.png" srcset="/img/loading.gif" lazyload alt="The architectures of generator and discriminator"></p>
<h3 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h3><p>Detection network backbone: YOLOv5</p>
<p>Generator:<br>1.Structural similarity index (SSIM)</p>
<blockquote>
<p>Contributes to generate a fused image that preserves overall structures and maintains a similar intensity distribution as source images.</p>
</blockquote>
<p>  <img src="/img/stage1/14.png" srcset="/img/loading.gif" lazyload alt="Generator loss SSIM"></p>
<p>2.Pixel loss (based on the saliency degree weight (SDW))</p>
<blockquote>
<p>To balance the pixel intensity distribution of source images</p>
</blockquote>
<p>  <img src="/img/stage1/15.png" srcset="/img/loading.gif" lazyload alt="Pixel Loss"><br>  w1, w2 are calculated by saliency value of x and y.</p>
<p>Target and detail discriminators:<br>Wasserstein divergence (with target mask m)</p>
<blockquote>
<p>The target discriminator D_T is used to distinguish the foreground thermal targets of fused result to the infrared while the detail discriminator D_D contributes to distinguish the background details of fused result to the visible.<br>  PS：_ 代表下标，^ 代表上标</p>
</blockquote>
<p>  <img src="/img/stage1/16.png" srcset="/img/loading.gif" lazyload alt="Discriminator loss"></p>
<h2 id="SeAFusion"><a href="#SeAFusion" class="headerlink" title="SeAFusion"></a>SeAFusion</h2><h3 id="Title-1"><a href="#Title-1" class="headerlink" title="Title"></a>Title</h3><p>Image fusion in the loop of high-level vision tasks: A semantic-aware real-time infrared and visible image fusion network [Image Fusion]</p>
<h3 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h3><p>The infrared sensor captures thermal radiation emitted from objects, which could highlight salient targets, but the infrared image neglects texture and is vulnerable to noise. </p>
<p>The visible sensor captures reflective light infomation, the visible image usually contains abundant texture and structure info, but is sensitive to the environment, such as illumination and occlusion.</p>
<p>Complementary info: to fuse Ir and Vis image, to generate a desired image.</p>
<p>Fused image has been broadly used as a preprocessing module for high-level vision tasks, e.g., object detection, tracking, semantic segmentation.</p>
<h3 id="Motivation-1"><a href="#Motivation-1" class="headerlink" title="Motivation"></a>Motivation</h3><p>Pressing challenges:</p>
<div class="code-wrapper"><pre><code class="hljs livecodeserver"><span class="hljs-number">1.</span>The existing fusion algorithms are inclined <span class="hljs-built_in">to</span> pursue better visual quality
<span class="hljs-keyword">and</span> higher evaluation metrics but seldom systematically consider
whether fused image can facilitate high-level vision tasks
  &gt; Some studies: cannot effectively enhance/boost <span class="hljs-keyword">the</span> semantic info <span class="hljs-keyword">in</span> <span class="hljs-keyword">the</span> fused image

<span class="hljs-number">2.</span>Neither visual comparison nor quantitative evaluation (evaluation manners)
reflects <span class="hljs-keyword">the</span> facilitation <span class="hljs-keyword">of</span> fused images <span class="hljs-keyword">for</span> high-level vision tasks

<span class="hljs-number">3.</span>Not <span class="hljs-keyword">effective</span> <span class="hljs-keyword">in</span> extracting fine-grained detail features

<span class="hljs-number">4.</span>Ignore <span class="hljs-keyword">the</span> demand <span class="hljs-keyword">for</span> real-<span class="hljs-built_in">time</span> image fusion</code></pre></div>

<p>Ours network:</p>
<p>SeAFusion, can be used for achieving real-time Ir &amp; Vis image fusion</p>
<h3 id="Method-1"><a href="#Method-1" class="headerlink" title="Method"></a>Method</h3><div class="code-wrapper"><pre><code class="hljs pgsql"><span class="hljs-number">1.</span>Simultaneously obtaining superior performance <span class="hljs-keyword">in</span>
<span class="hljs-keyword">both</span> image fusion <span class="hljs-keyword">and</span> high-<span class="hljs-keyword">level</span> vision tasks.

<span class="hljs-number">2.</span>A segmentation network <span class="hljs-keyword">to</span> predict the segmentation results
<span class="hljs-keyword">on</span> fused images, which <span class="hljs-keyword">is</span> utilized <span class="hljs-keyword">to</span> construct semantic loss
(<span class="hljs-keyword">is</span> leveraged <span class="hljs-keyword">to</span> guide the training <span class="hljs-keyword">of</span> the fusion network via back-propagation, 
so the loss can flow back <span class="hljs-keyword">to</span> the image fusion module
<span class="hljs-keyword">to</span> forcing fused images <span class="hljs-keyword">to</span> contain more semantic infomation).

<span class="hljs-number">3.</span><span class="hljs-type">Real</span>-<span class="hljs-type">time</span>: light-weight network based <span class="hljs-keyword">on</span> GRDB (gradient residual dense block)
<span class="hljs-keyword">to</span> boost the description ability <span class="hljs-keyword">for</span> fine-grained details <span class="hljs-keyword">and</span> achieve feature reuse.

<span class="hljs-number">4.</span>The authors proposed a joint low-<span class="hljs-keyword">level</span> <span class="hljs-keyword">and</span> high-<span class="hljs-keyword">level</span> adaptive training strategy
<span class="hljs-keyword">to</span> achieve simultaneously impressive performance <span class="hljs-keyword">in</span> <span class="hljs-keyword">both</span>
image fusion <span class="hljs-keyword">and</span> various high-<span class="hljs-keyword">level</span> vision tasks.</code></pre></div>

<h3 id="Structure-diagram-1"><a href="#Structure-diagram-1" class="headerlink" title="Structure diagram"></a>Structure diagram</h3><p><img src="/img/stage1/21.png" srcset="/img/loading.gif" lazyload alt="The overall framework of the proposed semantic-aware infrared and visible image fusion algorithm."></p>
<p><img src="/img/stage1/22.png" srcset="/img/loading.gif" lazyload alt="The architecture of the real-time infrared and visible image fusion network based on gradient residual dense block."></p>
<p><img src="/img/stage1/23.png" srcset="/img/loading.gif" lazyload alt="The specific devise of the gradient residual dense block. The Sobel operator is selected as the Gradient Operator to extract fine-grained detail information of feature maps."></p>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p><img src="/img/stage1/24.png" srcset="/img/loading.gif" lazyload alt="Analysis1: fusion network"></p>
<p><img src="/img/stage1/25.png" srcset="/img/loading.gif" lazyload alt="Analysis2: segmentation network"><br>注：分割网络是另一篇论文的内容</p>
<p><img src="/img/stage1/26.png" srcset="/img/loading.gif" lazyload alt="Algorithm"></p>
<h2 id="SegMiF"><a href="#SegMiF" class="headerlink" title="SegMiF"></a>SegMiF</h2><h3 id="Title-2"><a href="#Title-2" class="headerlink" title="Title"></a>Title</h3><p>Multi-interactive Feature Learning and a Full-time Multi-modality Benchmark for Image Fusion and Segmentation [ICCV]</p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>Early efforts boost performance for only one task.</p>
<p>This paper, SegMiF can dual-task correlation to promote the performance of both tasks (fusion and segmentation).</p>
<h3 id="Intro-1"><a href="#Intro-1" class="headerlink" title="Intro"></a>Intro</h3><p>Contributions:</p>
<div class="code-wrapper"><pre><code class="hljs sql"><span class="hljs-number">1.</span>SegMiF <span class="hljs-keyword">contains</span> two modules, i.e., <span class="hljs-keyword">fusion</span> network
<span class="hljs-keyword">and</span> common segmentation network.

<span class="hljs-number">2.</span>Hierarchical interactive attention (HIA) block. 
Fine<span class="hljs-operator">-</span>grained mapping <span class="hljs-keyword">of</span> <span class="hljs-keyword">all</span> the vital infomation <span class="hljs-keyword">between</span> <span class="hljs-keyword">fusion</span> <span class="hljs-keyword">and</span> segmentation. 
Modality<span class="hljs-operator">-</span><span class="hljs-operator">/</span>Semantic<span class="hljs-operator">-</span> oriented features can be fully mutual<span class="hljs-operator">-</span>interactive
(bridge the feature gap <span class="hljs-keyword">between</span> <span class="hljs-keyword">fusion</span> <span class="hljs-keyword">and</span> segmentation).

<span class="hljs-number">3.</span><span class="hljs-keyword">Dynamic</span> weight factor, automatically adjust the <span class="hljs-keyword">corresponding</span> weights
<span class="hljs-keyword">of</span> <span class="hljs-keyword">each</span> task (optimal parameters).

<span class="hljs-number">4.</span>Interactive feature training scheme.

<span class="hljs-number">5.</span>Construct an imaging <span class="hljs-keyword">system</span> (benchmark).</code></pre></div>

<h3 id="Structure-diagram-2"><a href="#Structure-diagram-2" class="headerlink" title="Structure diagram"></a>Structure diagram</h3><p><img src="/img/stage1/31.png" srcset="/img/loading.gif" lazyload alt="Workflow of the proposed SegMiF. The left part depicts the latent interactive relationship between image fusion and segmentation. The middle part plots the concrete architecture of the SegMiF. The right part details the components of proposed hierarchical interactive attention."></p>
<p><img src="/img/stage1/32.png" srcset="/img/loading.gif" lazyload alt="Partial zoom"></p>
<h3 id="分析-1"><a href="#分析-1" class="headerlink" title="分析"></a>分析</h3><p><img src="/img/stage1/33.png" srcset="/img/loading.gif" lazyload alt="Fusion network and DRDB module"></p>
<p><img src="/img/stage1/34.png" srcset="/img/loading.gif" lazyload alt="Detailed architectures of SoAM and MoAM"></p>
<div class="code-wrapper"><pre><code class="hljs oxygene">HIA:

<span class="hljs-number">1</span>.SoAM (Semantic-oriented attention <span class="hljs-keyword">module</span>)
  SoAM utilizes the token F_seg^s <span class="hljs-keyword">to</span> generate the query Q_s,
  which represents the inhere semantic information that needs <span class="hljs-keyword">to</span> be enhanced.

  The <span class="hljs-keyword">global</span> context representation <span class="hljs-keyword">of</span> <span class="hljs-keyword">each</span> can be calculated <span class="hljs-keyword">by</span> <span class="hljs-keyword">as</span>
  K_ir^T · V_ir (G_ir) <span class="hljs-keyword">and</span> K_vis^T · V_vis (G_vis)
  K, V ∈ <span class="hljs-comment">&#123;F_ir^s, F_vis^s&#125;</span>
  S_ir = Q_s · G_ir, S_vis = Q_s · G_vis
  
  SoAM <span class="hljs-keyword">to</span> provide more semantic attention <span class="hljs-keyword">for</span> the modality feature.

<span class="hljs-number">2</span>.MoAM (Modality-oriented attention <span class="hljs-keyword">module</span>)
  MoAM introduce two modality queries Q_ir <span class="hljs-keyword">and</span> Q_vis ∈ <span class="hljs-comment">&#123;F_ir^m, F_vis^m&#125;</span>
  
  The <span class="hljs-keyword">global</span> context <span class="hljs-keyword">of</span> segmentation G_s <span class="hljs-keyword">by</span> K_s^T · V_s
  M_ir = Q_ir · G_s, M_vis = Q_vis · G_s

  MoAM <span class="hljs-keyword">to</span> investigate the significant feature <span class="hljs-keyword">from</span> semantic contexts.</code></pre></div>

<p><img src="/img/stage1/35.png" srcset="/img/loading.gif" lazyload alt="Joint formulation"></p>
<p>待更新。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Learning/" class="category-chain-item">Learning</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/summarize/" class="print-no-link">#summarize</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>文献整理</div>
      <div>https://afly36-swordsman.github.io/2023/11/25/Papers/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Zenitsu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>November 25, 2023</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Updated on</div>
          <div>November 28, 2023</div>
        </div>
      
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/11/25/Professional/" title="专业笔记">
                        <span class="hidden-mobile">专业笔记</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">

  <div>
    <span id="timeDate">正在载入天数...</span>
    <span id="times">载入时分秒...</span>
    <script>
    var now = new Date();
    function createtime(){
        var grt= new Date("11/24/2023 11:30:00");
        now.setTime(now.getTime()+250);
        days = (now - grt ) / 1000 / 60 / 60 / 24;
        dnum = Math.floor(days);
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum);
        hnum = Math.floor(hours);
        if(String(hnum).length ==1 ){
            hnum = "0" + hnum;
        }
        minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum);
        mnum = Math.floor(minutes);
        if(String(mnum).length ==1 ){
                  mnum = "0" + mnum;
        }
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum);
        snum = Math.round(seconds);
        if(String(snum).length ==1 ){
                  snum = "0" + snum;
        }
        document.getElementById("timeDate").innerHTML = "🚀 for&nbsp"+dnum+"&nbspdays";  
        document.getElementById("times").innerHTML = hnum + "&nbsphr&nbsp" + mnum + "&nbspmin&nbsp" + snum + "&nbspsec";
    }
    setInterval("createtime()",250);
    </script>
  </div>  

  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  

</div>
  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>




  
<script src="/js/custom.js"></script>



<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>

</body>
</html>
